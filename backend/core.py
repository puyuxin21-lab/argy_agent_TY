import os
# âœ… æ­£ç¡®çš„å†™æ³•
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv, find_dotenv

# --- é…ç½® ---
#os.environ["OPENAI_API_KEY"] = "sk-i0HXYWyGQZ6v5VKdoM0alDBvTpPD8GxVHja1ex6rR0lfP29G"
#os.environ["OPENAI_API_BASE"] = "https://api.openai-proxy.org/v1"
#os.environ["HF_ENDPOINT"] = "https://hf-mirror.com" # å›½å†…é•œåƒ
#API_KEY=os.getenv("OPENAI_API_KEY")
#API_BASE=os.getenv("OPENAI_API_BASE")
load_dotenv(find_dotenv(),override=True)
HF_ENDPOINT=os.getenv("HF_ENDPOINT")

INDEX_PATH = "faiss_index_store"
DATA_PATH = "../data"#æ³¨æ„ï¼šç›¸å¯¹äº backendæ–‡ä»¶å¤¹ï¼Œdataåœ¨ä¸Šä¸€çº§
LOCAL_MODEL_NAME = os.getenv("LOCAL_MODEL_NAME")

class AllergyAgentAI:
    def __init__(self):
        """åˆå§‹åŒ–æ—¶åŠ è½½æœ¬åœ°æ¨¡å‹"""
        print(f"[AI Core] æ­£åœ¨åŠ è½½æœ¬åœ°æ¨¡å‹: {LOCAL_MODEL_NAME} ...")
        try:
            self.embeddings = HuggingFaceEmbeddings(
            model_name=LOCAL_MODEL_NAME,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
            )
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.embeddings = None
        self.vectorstore = None
        self.load_vector_store()#å°è¯•åŠ è½½å·²æœ‰ç´¢å¼•

    def load_vector_store(self):
        """å°è¯•ä»ç¡¬ç›˜åŠ è½½ç´¢å¼•"""
        if os.path.exists(INDEX_PATH):
            try:
                self.vectorstore = FAISS.load_local(
                    INDEX_PATH,
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
                print("[AI Core] æˆåŠŸåŠ è½½æœ¬åœ°çŸ¥è¯†åº“ç´¢å¼•")
            except Exception as e:
                print("[AI Core] åŠ è½½ç´¢å¼•å¤±è´¥: {e}")
        else:
            print("[AI Core] æœªæ‰¾åˆ°æœ¬åœ°ç´¢å¼•ï¼Œè¯·å…ˆæ‰§è¡Œé‡å»ºçŸ¥è¯†åº“")

    def rebuild_knowledge_base(self):
        """é‡å»ºçŸ¥è¯†åº“(ETL æµç¨‹)"""
        if not os.path.exists(DATA_PATH):
            os.makedirs(DATA_PATH)
            return {"status":"error","message":f"æœªæ‰¾åˆ°æ•°æ®ç›®å½•{DATA_PATH}"}

        #1.è¯»å–
        loader = DirectoryLoader(DATA_PATH,glob="**/*.txt",loader_cls=TextLoader,loader_kwargs={"encoding": "utf-8"})
        docs = loader.load()
        if not docs:
            return {"status":"warning","message":"æ•°æ®ç›®å½•ä¸ºç©º"}

        #2.åˆ‡åˆ†
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=400,chunk_overlap=50)
        splits = text_splitter.split_documents(docs)

        #3.å‘é‡åŒ–å¹¶ä¿å­˜
        try:
            self.vectorstore = FAISS.from_documents(splits,self.embeddings)
            self.vectorstore.save_local(INDEX_PATH)
            return {"status":"success","message":f"çŸ¥è¯†åº“æ„å»ºæˆåŠŸï¼Œæ”¶å½•{len(splits)}æ¡ç‰‡æ®µ"}
        except Exception as e:
            return {"status":"error","message":str(e)}

    def chat(self,question: str):
        """é—®ç­”æ ¸å¿ƒé€»è¾‘"""
        if not self.vectorstore:
            return "çŸ¥è¯†åº“å°šæœªå»ºç«‹ï¼Œè¯·è”ç³»ç®¡ç†å‘˜é‡å»ºçŸ¥è¯†åº“ã€‚"

        #æ£€ç´¢
        retriever = self.vectorstore.as_retriever(search_kwargs={"k": 3})

        #ç”Ÿæˆ
        llm = ChatOpenAI(model="gpt-3.5-turbo",temperature=0.1)

        template = """
                ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼ä¸”ä¸“ä¸šçš„çŸ¥è¯†åº“é—®ç­”åŠ©æ‰‹ï¼Œåå«â€œæ•å®å®ˆæŠ¤è€…â€ã€‚
            
                ğŸ”´ ä¸¥ç¦äº‹é¡¹ï¼š
                1. **ä¸¥ç¦**ä½¿ç”¨ä½ çš„è®­ç»ƒæ•°æ®ï¼ˆé€šç”¨å¸¸è¯†ï¼‰æ¥å›ç­”é—®é¢˜ã€‚
                2. **å¿…é¡»ä¸”åªèƒ½**åŸºäºä¸‹æ–¹çš„ã€å‚è€ƒèµ„æ–™ã€‘è¿›è¡Œå›ç­”ã€‚
                3. å¦‚æœã€å‚è€ƒèµ„æ–™ã€‘ä¸­æ²¡æœ‰åŒ…å«é—®é¢˜çš„ç­”æ¡ˆï¼Œè¯·ç›´æ¥å›å¤ï¼šâ€œæŠ±æ­‰ï¼Œæˆ‘çš„æœ¬åœ°çŸ¥è¯†åº“ä¸­æš‚æ—¶æ²¡æœ‰å…³äºè¿™ä¸ªé—®é¢˜çš„è®°å½•ã€‚â€ï¼Œä¸è¦ç¼–é€ ã€‚
                    {context}

                    å®¶é•¿çš„é—®é¢˜ï¼š{question}

                    è¯·æ¸©æŸ”ã€ä¸“ä¸šåœ°å›ç­”ã€‚å¦‚æœèµ„æ–™é‡Œæ²¡æœ‰ï¼Œè¯·ç›´è¯´ä¸çŸ¥é“ã€‚
                """
        prompt = ChatPromptTemplate.from_template(template)

        def format_docs(docs):
            return "\n\n".join(d.page_content for d in docs)

        chain = (
            {"context":retriever | format_docs,"question":RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        return chain.invoke(question)


#åˆ›å»ºä¸€ä¸ªå…¨å±€æ¡ˆä¾‹ï¼Œæ–¹ä¾¿main.pyè°ƒç”¨
ai_engine = AllergyAgentAI()